{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "hw1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X3yg8s5c4GC",
        "colab_type": "text"
      },
      "source": [
        "<div id=\"top\"></div> \n",
        "# Table of contents\n",
        "* <a href='#Submission-instructions'>Submission instructions</a>\n",
        "* <a href=\"#A-short-introduction-to-LaTeX\">A short introduction to LaTeX</a>\n",
        "* <a href=\"#Some-useful-numpy-functions\">Some useful numpy functions</a>\n",
        "* <a href=\"#The-start-of-this-homework\">The start of this homework</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EenkzVIELWuR",
        "colab_type": "text"
      },
      "source": [
        "# HW 1 \n",
        "## By: Mansi Sakarvadia, Nathaniel (Nate) Fulmer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_acIvMXMc4GD",
        "colab_type": "text"
      },
      "source": [
        "# Submission instructions\n",
        "See announcement on Sakai for instructions. Do NOT email the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o4ooC05c4GE",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"#top\">top</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLXzIWv0c4GF",
        "colab_type": "text"
      },
      "source": [
        "# A short introduction to LaTeX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6UlPOUmc4GF",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "$ \\LaTeX $ is a markup language to typeset documents. You can use it to express math compactly and make the layout of your documents beautiful. For the purpose of this class, we focus on the first piece, that is writing mathematical formulations. Jupyter implements a subset of $\\LaTeX$. Therefore, you can use $ \\LaTeX $ to answers the problems in the assignments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDAFF8lyc4GG",
        "colab_type": "text"
      },
      "source": [
        "## Two modes in latex that can typeset the formulations\n",
        "1. Inline mode, start with an \\$, end with an \\$ (\\$...\\$). E.g. $a + b = \\frac{1}{3}$\n",
        "2. Display mode, start with two \\$\\$, end with two \\$\\$ (\\$\\$...\\$\\$). E.g. $$a+b=\\frac{1}{3}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH4kXFjkc4GH",
        "colab_type": "text"
      },
      "source": [
        "## Basic Maths\n",
        "1. It is straight-forward for basic arithmetic operations. E.g. $+, - * /, a^b, a_b$.\n",
        "2. $ \\LaTeX$ already defined many useful symbols, macros, (or functions) to typeset the formulations. They start with \\, such as \\LaTeX is for the latex symbol. In some typeset functions you can give them parameters. E.g. \\frac{1}{3} typesets one over three, where the thing within the first {} is nominator, and the thing within the second {} is denominator. {} also helps group thing within it together. Consider the difference between a\\_b+1 ($a_b+1$) and a\\_{b+1} ($a_{b+1}$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWoZuhUdc4GI",
        "colab_type": "text"
      },
      "source": [
        "## Useful symbols and functions\n",
        "1. fraction, \\frac{1}{3}. ($\\frac{1}{3}$)\n",
        "2. partial derivative, \\partial. ($\\partial$), Combined with 1), we have \\frac{\\partial f}{\\partial x}. ($\\frac{\\partial f}{\\partial x}$)\n",
        "3. summation, \\sum\\_{i=1}^{N}. ($\\sum_{i=1}^{N}$)\n",
        "4. products, \\prod\\_{i=1}^{N}. ($\\prod_{i=1}^{N}$)\n",
        "5. indexing, w\\_{i, j}. ($w_{i, j}$)\n",
        "6. frequently used Greek letters \\alpha, \\beta, \\gamma. ($\\alpha, \\beta, \\gamma$)\n",
        "7. gradient notation \\nabla. ($\\nabla$)\n",
        "8. vector forms $\\text{\\\\begin{bmatrix} x_{i, 1} \\\\ \\vdots \\\\ x_{i, p+1}  \\\\end{bmatrix}}$. ($\\begin{bmatrix} x_{i, 1} \\\\ \\vdots \\\\ x_{i, p+1} \\end{bmatrix}$) <br \\>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Weg71uc4GI",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"#top\">top</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJcmTtXFc4GJ",
        "colab_type": "text"
      },
      "source": [
        "# Some useful numpy functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXbfJ3Vhc4GK",
        "colab_type": "text"
      },
      "source": [
        "People usualy import numpy as the follow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBCxNDB0c4GL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRUq9DTuc4GP",
        "colab_type": "text"
      },
      "source": [
        "Here we introduce some useful numpy functions that you might use in this homework.\n",
        "* zeros <br \\>\n",
        "zeros generates a multi-dimensional array that contains all zeros. <br \\>\n",
        "    * Example: <br \\>\n",
        "    ** zeros( (3, 2) ) ** generates a 2d array of size 3\\*2 (three rows and 2 columns) that contains zeros in all entries. <br \\>\n",
        "    ** zeros( (3, 2, 4) )** generates a 3d array of size 3\\*2\\*4 that also contains zero in all entries.\n",
        "* ones <br \\>\n",
        "Similar to zeros, ones generates a multi-dimensional array that contains all ones. <br \\>\n",
        "* exp <br \\>\n",
        "exp takes exponential on each entry of the input. <br \\>\n",
        "    * Example: <br \\>\n",
        "    ** exp(3) ** computes $ e^3 $. <br \\>\n",
        "    ** exp( [1, 2, 3] ) ** computes $[ e^1, e^2, e^3]$.\n",
        "* log <br \\>\n",
        "Similar to exp, log takes log on each entry of the input. Since log function is not defined on the values $<= 0$, if the input of log is like that, it will output nan or inf defined in numpy. <br \\>\n",
        "* sum <br \\>\n",
        "sum takes sum over an axis of the input array. <br \\>\n",
        "    * Example: please see the following code cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT4E98_bc4GQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "47d1363c-9336-4a85-d656-29fe0e3b4ceb"
      },
      "source": [
        "matrixA = np.arange(9).reshape(3, 3)\n",
        "print( 'input array is a 3*3 matrix, values: \\n', matrixA )\n",
        "result1 = np.sum(matrixA, axis = 0)\n",
        "result2 = np.sum(matrixA, axis = 1)\n",
        "print( 'result 1 is ', result1 )\n",
        "print( 'result 2 is ', result2 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input array is a 3*3 matrix, values: \n",
            " [[0 1 2]\n",
            " [3 4 5]\n",
            " [6 7 8]]\n",
            "result 1 is  [ 9 12 15]\n",
            "result 2 is  [ 3 12 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SRzIIUHc4GV",
        "colab_type": "text"
      },
      "source": [
        "* dot <br \\>\n",
        "do dot-product of the two inputs (if they are vectors), or do matrix multiplication of the two inputs (if they are 2d arrays). In numpy if A and B are both arrays, A\\*B computes the element-wise multiplication, not matrix multiplication. To use dot, the dimensions of the two inputs must be valid. <br \\>\n",
        "    * Example: please see the following code cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxUydb5Bc4GW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fa0c7da9-27c7-44e8-f4ee-546d1d60560a"
      },
      "source": [
        "#dot product examples\n",
        "vector1 = np.array( [1, 2, 3] )\n",
        "vector2 = np.array( [1, 2, 1] )\n",
        "print( 'vecotr 1 is a length-3 vector, values: ', vector1 )\n",
        "print( 'vecotr 2 is a length-3 vector, values: ', vector2 )\n",
        "print( 'dot product of vecotr 1 and 2 is', np.dot(vector1, vector2) )\n",
        "vector3 = np.array( [1, 2, 1, 2])\n",
        "print( 'dot product of vecotr 1 and 3 generates error' )\n",
        "#np.dot(vector1, vector3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vecotr 1 is a length-3 vector, values:  [1 2 3]\n",
            "vecotr 2 is a length-3 vector, values:  [1 2 1]\n",
            "dot product of vecotr 1 and 2 is 8\n",
            "dot product of vecotr 1 and 3 generates error\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP72ULqzc4Ga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "527f0c43-f279-40ac-8624-649dc359920a"
      },
      "source": [
        "#matrix multiplication examples\n",
        "matrix1 = np.arange(6).reshape(2, 3)\n",
        "matrix2 = np.ones(((3,1)))\n",
        "print( 'matrix1 is a 2*3 matrix, values: \\n ', matrix1 )\n",
        "print( 'matrix2 is a 3*1 matrix, values: \\n ', matrix2 )\n",
        "print( 'matrix1 multiplies matrix2 is a 2*1 matrix: \\n ', np.dot(matrix1, matrix2) )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "matrix1 is a 2*3 matrix, values: \n",
            "  [[0 1 2]\n",
            " [3 4 5]]\n",
            "matrix2 is a 3*1 matrix, values: \n",
            "  [[1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "matrix1 multiplies matrix2 is a 2*1 matrix: \n",
            "  [[ 3.]\n",
            " [12.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BczRxYTvc4Ge",
        "colab_type": "text"
      },
      "source": [
        "* T <br \\>\n",
        "[numpy matrix variable].T, takes transpose of the input matrix variable.\n",
        "    * Example: please see the following code cell <br \\>\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydSWj9Fdc4Gh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6446d2e0-dda4-47fd-97f1-66a65363ae2c"
      },
      "source": [
        "matrix1 = np.ones( (4, 3) )\n",
        "print( 'matrix dimension is',  matrix1.shape )\n",
        "print( 'matrix dimension after transpose is', matrix1.T.shape )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "matrix dimension is (4, 3)\n",
            "matrix dimension after transpose is (3, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmaLewJoc4Gn",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"#top\">top</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_elh2tjPc4Go",
        "colab_type": "text"
      },
      "source": [
        "# The start of this homework\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDYjxzIXc4Go",
        "colab_type": "text"
      },
      "source": [
        "# Import plotting utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBz0EUeLc4Gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95W5XcbLc4Gs",
        "colab_type": "text"
      },
      "source": [
        "# Download and load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjfilLNVc4Gs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "52106e89-3189-4105-c09d-9bdc5e7a6824"
      },
      "source": [
        "#download data\n",
        "import time\n",
        "import urllib\n",
        "import os.path\n",
        "import sys\n",
        "versionName = sys.version_info\n",
        "if versionName[0] == 2:\n",
        "    import urllib as U\n",
        "elif versionName[0] == 3:\n",
        "    import urllib.request as U\n",
        "start = time.time()\n",
        "print(\"Should take at most 30 seconds\")\n",
        "if not os.path.isfile('train_data.pgz'):\n",
        "    U.urlretrieve(\"https://sakai.unc.edu/access/content/group/c4f84923-328b-429b-a8dc-a340b0284e41/HW1/train_data.pgz\", \"train_data.pgz\")\n",
        "if not os.path.isfile('test_data.pgz'):\n",
        "    U.urlretrieve(\"https://sakai.unc.edu/access/content/group/c4f84923-328b-429b-a8dc-a340b0284e41/HW1/test_data.pgz\", \"test_data.pgz\")\n",
        "if not os.path.isfile('vocab_list.pgz'):\n",
        "    U.urlretrieve( \"https://sakai.unc.edu/access/content/group/c4f84923-328b-429b-a8dc-a340b0284e41/HW1/vocab_list.pgz\", \"vocab_list.pgz\" );\n",
        "end = time.time()\n",
        "print(\"Time elapsed (seconds):\", end-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Should take at most 30 seconds\n",
            "Time elapsed (seconds): 5.3378143310546875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU8U2tP2gvP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "eb7edb5e-e6d2-4fbd-c371-c06753ff7b73"
      },
      "source": [
        "#Manually Uploading Files to Notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/3wGNeaaQsr6Fytw_pze-tR6eGOsvVz8CueGlYR17oOdVKPPl-x-GLlU\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDldjVe1hoZL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "76676a1e-3ef0-415d-92bc-1a8f680484cf"
      },
      "source": [
        "#This is how we manually load the data to Colab - Nate I suggest you use the same directory naming conventions/structure so that the upload process is the same for both of us\n",
        "#In your google drive create a \"Colab Notebooks\" folder (I think google naturally creates this), then create \"Comp562\", then create \"HW1\"\n",
        "\n",
        "#Nate comment: I was getting weird behavior so I just added the initial thing to make sure it was starting in the right place\n",
        "%cd /content/drive/\n",
        "%cd My\\ Drive/\n",
        "%cd Colab\\ Notebooks/\n",
        "%cd Comp562/HW1/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/Colab Notebooks\n",
            "/content/drive/My Drive/Colab Notebooks/Comp562/HW1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz1StQ3rc4Gv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "067135c3-0a1e-43eb-9293-aa0333f48713"
      },
      "source": [
        "#load data\n",
        "try:\n",
        "    import cPickle as pickle\n",
        "    kwargs = {}\n",
        "except:\n",
        "    import _pickle as pickle\n",
        "    kwargs = {'encoding':'bytes'}\n",
        "    \n",
        "import gzip\n",
        "import numpy as np\n",
        "start = time.time()\n",
        "print(\"Should take about 15 seconds\")\n",
        "train_data, train_label = pickle.load( gzip.open( \"train_data.pgz\", \"rb\" ), **kwargs )\n",
        "train_label = np.asarray(train_label)\n",
        "test_data = pickle.load( gzip.open( \"test_data.pgz\", \"rb\" ),**kwargs )\n",
        "vocab_list = pickle.load( gzip.open( \"vocab_list.pgz\", \"rb\" ),**kwargs )\n",
        "end = time.time()\n",
        "print(\"Time elapsed (seconds):\", end-start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Should take about 15 seconds\n",
            "Time elapsed (seconds): 11.016495704650879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "e41K3e3Yc4G3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "6b7a4e75-df7d-4b52-e379-b328a27962a6"
      },
      "source": [
        "#Consider using small set of the data\n",
        "trainData = train_data[:10000, :]\n",
        "validData = train_data[10000:15000, :]\n",
        "trainLabel = train_label[:10000]\n",
        "validLabel = train_label[10000:15000]\n",
        "testData = test_data[:10000, :]\n",
        "print( vocab_list )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['able', 'absolutely', 'across', 'act', 'acted', 'acting', 'action', 'actor', 'actors', 'actress', 'actual', 'actually', 'add', 'admit', 'adult', 'adventure', 'age', 'ago', 'agree', 'air', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'amazing', 'america', 'american', 'among', 'amusing', 'animated', 'animation', 'annoying', 'another', 'anyone', 'anything', 'anyway', 'apart', 'apparently', 'appear', 'appears', 'appreciate', 'around', 'art', 'ask', 'atmosphere', 'attempt', 'attempts', 'attention', 'audience', 'average', 'avoid', 'away', 'awful', 'baby', 'back', 'background', 'bad', 'badly', 'band', 'based', 'basic', 'basically', 'battle', 'beautiful', 'beauty', 'became', 'become', 'becomes', 'begin', 'beginning', 'begins', 'behind', 'believable', 'believe', 'ben', 'best', 'better', 'beyond', 'big', 'biggest', 'bill', 'bit', 'bizarre', 'black', 'blood', 'body', 'book', 'books', 'bored', 'boring', 'box', 'boy', 'boys', 'break', 'brilliant', 'bring', 'brings', 'british', 'brother', 'brothers', 'brought', 'budget', 'bunch', 'business', 'buy', 'call', 'called', 'came', 'camera', 'cannot', 'car', 'care', 'career', 'cartoon', 'case', 'cast', 'casting', 'cat', 'caught', 'cause', 'century', 'certain', 'certainly', 'chance', 'change', 'character', 'characters', 'cheap', 'check', 'cheesy', 'child', 'children', 'choice', 'christmas', 'cinema', 'cinematography', 'city', 'class', 'classic', 'clear', 'clearly', 'clever', 'clich', 'close', 'co', 'cold', 'come', 'comedy', 'comes', 'comic', 'coming', 'comment', 'comments', 'common', 'company', 'compared', 'complete', 'completely', 'concept', 'consider', 'considering', 'control', 'convincing', 'cool', 'cop', 'copy', 'could', 'country', 'couple', 'course', 'cover', 'crap', 'crazy', 'create', 'created', 'credit', 'credits', 'creepy', 'crew', 'crime', 'cut', 'cute', 'dance', 'dancing', 'dark', 'daughter', 'david', 'day', 'days', 'de', 'dead', 'deal', 'death', 'decent', 'decided', 'decides', 'deep', 'definitely', 'depth', 'deserves', 'despite', 'development', 'dialog', 'dialogue', 'die', 'died', 'different', 'difficult', 'directed', 'directing', 'direction', 'director', 'directors', 'disappointed', 'disney', 'doctor', 'documentary', 'dog', 'done', 'doubt', 'dr', 'drama', 'dramatic', 'dream', 'due', 'dull', 'dumb', 'dvd', 'earlier', 'early', 'earth', 'easily', 'easy', 'editing', 'effect', 'effective', 'effects', 'effort', 'either', 'elements', 'else', 'emotional', 'end', 'ended', 'ending', 'ends', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'enough', 'entertaining', 'entertainment', 'entire', 'entirely', 'episode', 'episodes', 'era', 'escape', 'especially', 'etc', 'even', 'events', 'eventually', 'ever', 'every', 'everyone', 'everything', 'evil', 'exactly', 'example', 'excellent', 'except', 'exciting', 'expect', 'expected', 'expecting', 'experience', 'extremely', 'eye', 'eyes', 'face', 'fact', 'fails', 'fairly', 'fall', 'falls', 'familiar', 'family', 'famous', 'fan', 'fans', 'fantastic', 'fantasy', 'far', 'fast', 'father', 'favorite', 'fear', 'feature', 'features', 'feel', 'feeling', 'feels', 'felt', 'female', 'fi', 'fight', 'fighting', 'figure', 'filled', 'film', 'filmed', 'filmmakers', 'films', 'final', 'finally', 'find', 'finds', 'fine', 'fire', 'first', 'five', 'flat', 'flick', 'focus', 'follow', 'following', 'follows', 'footage', 'force', 'forced', 'forget', 'form', 'former', 'forward', 'found', 'four', 'free', 'french', 'friend', 'friends', 'front', 'full', 'fun', 'funny', 'future', 'game', 'gave', 'gay', 'general', 'genre', 'george', 'german', 'get', 'gets', 'getting', 'girl', 'girlfriend', 'girls', 'give', 'given', 'gives', 'giving', 'go', 'god', 'goes', 'going', 'gone', 'good', 'gore', 'got', 'great', 'greatest', 'group', 'guess', 'gun', 'guy', 'guys', 'hair', 'half', 'hand', 'hands', 'happen', 'happened', 'happens', 'happy', 'hard', 'hardly', 'hate', 'head', 'hear', 'heard', 'heart', 'hell', 'help', 'hero', 'high', 'highly', 'hilarious', 'history', 'hit', 'hold', 'hollywood', 'home', 'hope', 'horrible', 'horror', 'hot', 'hour', 'hours', 'house', 'however', 'huge', 'human', 'humor', 'husband', 'idea', 'ideas', 'imagine', 'imdb', 'important', 'impressive', 'including', 'incredible', 'incredibly', 'indeed', 'inside', 'instead', 'intelligent', 'interest', 'interested', 'interesting', 'involved', 'island', 'italian', 'jack', 'james', 'jane', 'japanese', 'job', 'joe', 'john', 'joke', 'jokes', 'keep', 'keeps', 'kept', 'kid', 'kids', 'kill', 'killed', 'killer', 'killing', 'kills', 'kind', 'king', 'knew', 'know', 'known', 'knows', 'la', 'lack', 'lady', 'lame', 'language', 'large', 'last', 'late', 'later', 'laugh', 'laughing', 'laughs', 'law', 'lead', 'leading', 'leads', 'learn', 'least', 'leave', 'leaves', 'lee', 'left', 'less', 'let', 'level', 'life', 'light', 'like', 'liked', 'line', 'lines', 'list', 'little', 'live', 'lives', 'living', 'local', 'long', 'look', 'looked', 'looking', 'looks', 'lost', 'lot', 'lots', 'love', 'loved', 'low', 'mad', 'made', 'main', 'major', 'make', 'makes', 'making', 'male', 'man', 'manages', 'many', 'mark', 'married', 'mary', 'masterpiece', 'match', 'material', 'matter', 'may', 'maybe', 'mean', 'means', 'meant', 'meet', 'meets', 'members', 'memorable', 'men', 'mention', 'mentioned', 'mess', 'message', 'michael', 'middle', 'might', 'mind', 'minute', 'minutes', 'miss', 'missed', 'missing', 'modern', 'moment', 'moments', 'money', 'monster', 'mostly', 'mother', 'move', 'moves', 'movie', 'movies', 'moving', 'mr', 'much', 'murder', 'music', 'musical', 'must', 'mystery', 'name', 'named', 'nature', 'near', 'nearly', 'need', 'needed', 'needs', 'neither', 'never', 'new', 'next', 'nice', 'night', 'non', 'none', 'note', 'nothing', 'novel', 'nudity', 'number', 'obvious', 'obviously', 'odd', 'office', 'often', 'oh', 'ok', 'okay', 'old', 'older', 'one', 'ones', 'open', 'opening', 'opinion', 'order', 'original', 'oscar', 'others', 'otherwise', 'outside', 'overall', 'pace', 'parents', 'part', 'particular', 'particularly', 'parts', 'party', 'past', 'paul', 'pay', 'people', 'perfect', 'perfectly', 'performance', 'performances', 'perhaps', 'period', 'person', 'personal', 'peter', 'picture', 'piece', 'place', 'plain', 'planet', 'play', 'played', 'playing', 'plays', 'please', 'plenty', 'plot', 'plus', 'point', 'pointless', 'points', 'police', 'political', 'poor', 'poorly', 'popular', 'portrayal', 'portrayed', 'positive', 'possible', 'possibly', 'potential', 'power', 'powerful', 'predictable', 'premise', 'present', 'pretty', 'previous', 'probably', 'problem', 'problems', 'produced', 'production', 'public', 'pure', 'put', 'quality', 'question', 'quickly', 'quite', 'rate', 'rated', 'rather', 'rating', 'read', 'reading', 'real', 'realistic', 'reality', 'realize', 'really', 'reason', 'reasons', 'recent', 'recently', 'recommend', 'red', 'relationship', 'release', 'released', 'remake', 'remember', 'rent', 'respect', 'rest', 'result', 'return', 'revenge', 'review', 'reviews', 'rich', 'richard', 'ridiculous', 'right', 'robert', 'rock', 'role', 'roles', 'romance', 'romantic', 'room', 'run', 'running', 'runs', 'sad', 'sadly', 'said', 'save', 'saw', 'say', 'saying', 'says', 'scary', 'scene', 'scenes', 'school', 'sci', 'science', 'score', 'scott', 'screen', 'screenplay', 'script', 'season', 'second', 'secret', 'see', 'seeing', 'seem', 'seemed', 'seems', 'seen', 'sees', 'self', 'sense', 'sequel', 'sequence', 'sequences', 'series', 'serious', 'seriously', 'set', 'sets', 'setting', 'several', 'sex', 'sexual', 'shame', 'short', 'shot', 'shots', 'show', 'showing', 'shown', 'shows', 'side', 'silly', 'similar', 'simple', 'simply', 'since', 'singing', 'single', 'sister', 'sit', 'situation', 'slightly', 'slow', 'small', 'social', 'society', 'solid', 'somehow', 'someone', 'something', 'sometimes', 'somewhat', 'son', 'song', 'songs', 'soon', 'sorry', 'sort', 'sound', 'sounds', 'soundtrack', 'space', 'speak', 'special', 'spend', 'spent', 'spirit', 'spoilers', 'stage', 'stand', 'star', 'stars', 'start', 'started', 'starts', 'state', 'stay', 'still', 'stop', 'store', 'stories', 'story', 'storyline', 'straight', 'strange', 'street', 'strong', 'studio', 'stuff', 'stupid', 'style', 'subject', 'success', 'successful', 'suddenly', 'super', 'superb', 'supporting', 'supposed', 'sure', 'surprise', 'surprised', 'suspense', 'sweet', 'take', 'taken', 'takes', 'taking', 'tale', 'talent', 'talented', 'talk', 'talking', 'team', 'television', 'tell', 'telling', 'tells', 'ten', 'tension', 'terrible', 'th', 'theater', 'theme', 'thing', 'things', 'think', 'thinking', 'third', 'though', 'thought', 'three', 'thriller', 'throughout', 'time', 'times', 'title', 'today', 'together', 'told', 'tom', 'tone', 'tony', 'took', 'top', 'total', 'totally', 'towards', 'town', 'trash', 'tried', 'tries', 'trouble', 'true', 'truly', 'truth', 'try', 'trying', 'turn', 'turned', 'turns', 'tv', 'twist', 'two', 'type', 'typical', 'ultimately', 'understand', 'unfortunately', 'unique', 'unless', 'unlike', 'upon', 'us', 'use', 'used', 'uses', 'using', 'usual', 'usually', 'value', 'various', 'version', 'video', 'view', 'viewer', 'viewers', 'viewing', 'villain', 'violence', 'violent', 'visual', 'voice', 'wait', 'waiting', 'walk', 'want', 'wanted', 'wants', 'war', 'waste', 'wasted', 'watch', 'watched', 'watching', 'water', 'way', 'ways', 'weak', 'weird', 'well', 'went', 'western', 'whatever', 'whether', 'white', 'whole', 'whose', 'wife', 'william', 'wish', 'within', 'without', 'woman', 'women', 'wonder', 'wonderful', 'word', 'words', 'work', 'worked', 'working', 'works', 'world', 'worse', 'worst', 'worth', 'would', 'write', 'writer', 'writers', 'writing', 'written', 'wrong', 'wrote', 'year', 'years', 'yes', 'yet', 'york', 'young', 'younger', 'zombie', 'zombies']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko1xLwdLc4G6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d33b8c4-ea74-4167-c74a-b7acbcc45403"
      },
      "source": [
        "train_data.mean(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.01049613e-15, -5.65727465e-16,  2.07511563e-15, -1.25034871e-15,\n",
              "        8.93827234e-16,  2.09658957e-16,  1.24238841e-15,  1.42255097e-16,\n",
              "        1.64055436e-15, -9.47040224e-16,  2.49471777e-15, -2.77537993e-16,\n",
              "       -1.35806033e-15, -2.28569386e-16, -4.80685491e-16,  4.10660395e-17,\n",
              "       -1.47469592e-15, -2.29052333e-16,  1.79992687e-15,  5.72459857e-16,\n",
              "       -7.98441313e-16, -7.43938244e-17, -1.37430067e-15, -4.51683135e-16,\n",
              "        5.87072613e-16, -1.25504496e-15,  7.40705275e-16, -1.24832367e-15,\n",
              "       -2.98550518e-15, -2.53230104e-15, -2.07554862e-15, -1.01518793e-17,\n",
              "        5.15988363e-16, -3.17301740e-16, -1.22530652e-15,  1.63173031e-15,\n",
              "       -1.02405640e-15, -4.67292871e-16, -3.91819910e-17, -1.19720900e-15,\n",
              "        2.47845300e-15, -1.31523681e-16,  6.25703933e-16,  2.51556553e-16,\n",
              "        1.78223658e-15, -1.40591760e-15,  7.31237293e-16, -8.80038264e-16,\n",
              "       -8.96323016e-16,  7.37727657e-16,  8.86091200e-16, -1.26235244e-15,\n",
              "       -4.65816274e-16,  7.35764782e-16, -9.39963662e-16,  3.27660121e-16,\n",
              "       -7.29555305e-16, -7.02549130e-17,  7.68816122e-16,  1.80150561e-15,\n",
              "       -1.61279656e-15,  8.43154435e-16,  1.01290087e-16, -8.83166873e-16,\n",
              "        1.22529320e-15, -1.20171983e-15, -1.47377222e-15, -1.69755321e-16,\n",
              "       -1.13765664e-15, -3.42539108e-15,  1.81495929e-15,  1.02292397e-15,\n",
              "       -5.55755442e-17, -1.03895559e-15, -7.87481191e-17,  7.18989313e-16,\n",
              "        9.81437154e-19,  9.75383108e-16, -7.74407205e-16, -8.23574542e-16,\n",
              "       -1.01402442e-15,  3.20503624e-16, -4.79116746e-16, -1.03097531e-16,\n",
              "        1.40933487e-15, -3.94573263e-16,  4.78002082e-16, -7.11430914e-18,\n",
              "       -2.43287612e-16,  2.28898456e-15, -1.43313361e-15,  1.46509249e-15,\n",
              "       -1.98862482e-15, -1.30762068e-17, -6.47351062e-16,  1.45788936e-16,\n",
              "        1.21128219e-15,  2.37354580e-16,  1.76745174e-15, -1.93071559e-15,\n",
              "        9.48741086e-16,  4.07502920e-16, -9.38817912e-16, -8.92610430e-16,\n",
              "        3.25179883e-16,  2.36988873e-15,  2.25215402e-16,  7.93161092e-16,\n",
              "       -2.62359023e-16, -1.17639232e-15,  5.67770275e-16, -6.75564049e-16,\n",
              "       -1.60262248e-15, -1.10456089e-15, -1.80880422e-15, -1.84725568e-16,\n",
              "        5.26514388e-16, -7.59681207e-17, -1.07724940e-15,  3.15438786e-16,\n",
              "        6.91339208e-16, -8.49844639e-16, -1.53317359e-16, -7.82891529e-16,\n",
              "        2.16185958e-15,  8.82476314e-16,  9.50794998e-17, -6.24167384e-16,\n",
              "        6.38027409e-16, -2.83209012e-16,  5.67299541e-16,  2.11542561e-15,\n",
              "       -1.32543532e-15,  1.21730181e-15, -1.62287073e-15,  2.84945401e-16,\n",
              "       -3.60791397e-16,  3.29047900e-17,  1.50068624e-15,  7.86022358e-16,\n",
              "        1.80736537e-15,  9.44642142e-16, -1.51694879e-15,  5.72326631e-16,\n",
              "        8.80964190e-16, -4.40654180e-16,  7.95490340e-16, -1.13306697e-15,\n",
              "        7.62645502e-16, -3.13096216e-16,  6.70317135e-16, -4.00874889e-16,\n",
              "        2.14348317e-15, -6.71880329e-16, -1.02675646e-16,  7.32527372e-16,\n",
              "       -1.14027232e-15,  4.82573981e-16,  1.19176446e-15, -6.91844360e-16,\n",
              "        3.82704979e-16, -4.89652763e-17, -1.51304747e-15,  2.28078889e-15,\n",
              "       -7.22819582e-16,  2.17898366e-15, -3.08735260e-16, -2.12693863e-15,\n",
              "        1.62317271e-15, -8.82129925e-16, -4.35361081e-15,  8.50559623e-16,\n",
              "       -2.59939625e-15,  7.69695419e-17,  7.42497175e-16, -3.76860765e-16,\n",
              "        5.08189046e-16,  3.69073661e-16, -3.37663231e-17, -3.99542621e-16,\n",
              "       -9.36388744e-16,  1.39301903e-16,  3.04852144e-15, -1.93018268e-15,\n",
              "       -4.64883687e-16, -6.18853857e-16, -1.20092269e-15,  9.00102215e-17,\n",
              "        2.85445001e-16,  6.46807052e-16, -2.77200485e-16,  3.23784111e-15,\n",
              "        1.80306992e-15, -9.08850772e-17, -2.87099011e-15, -1.35207401e-15,\n",
              "       -2.16898277e-15,  3.86011223e-16,  4.66371386e-16, -9.33495503e-16,\n",
              "        2.83064683e-16,  5.12265785e-16,  1.83225879e-15, -7.93938248e-16,\n",
              "        8.40549852e-17, -1.72857062e-15, -3.32640582e-16,  1.23729693e-15,\n",
              "        1.02066799e-15, -1.61660907e-15,  2.23810970e-15, -6.08701978e-16,\n",
              "        8.40421066e-16,  5.26723110e-16,  1.37731160e-15,  5.46973578e-16,\n",
              "       -6.82238710e-16, -1.51072599e-15, -2.85594881e-16,  1.84298299e-15,\n",
              "        5.03018738e-16, -1.25950361e-15, -2.99009706e-16,  1.03612785e-15,\n",
              "        6.08171291e-16, -1.97274419e-15, -1.04659392e-15, -6.35391739e-16,\n",
              "       -1.13860921e-15, -8.10260747e-16,  2.64699374e-16, -5.95927752e-16,\n",
              "        3.98461264e-16, -1.64336322e-15, -1.76401782e-15,  1.05438103e-15,\n",
              "        3.07598391e-17, -5.64719382e-16, -1.31222144e-15,  1.31936906e-15,\n",
              "       -1.87171167e-15, -4.21866986e-16, -1.16513688e-15,  3.51972229e-15,\n",
              "        1.25079502e-15,  6.43143316e-16, -2.81463741e-16,  7.26956273e-16,\n",
              "        9.42057543e-16,  9.05937547e-16,  2.52986521e-16,  1.69237069e-15,\n",
              "        9.67879110e-16,  1.90845117e-15,  1.70089054e-15,  5.67528247e-16,\n",
              "        1.29566802e-15, -8.01847477e-17, -9.83446657e-16,  9.03590536e-16,\n",
              "        1.78297155e-15,  2.50878207e-16, -1.36745726e-15,  7.34110550e-16,\n",
              "       -3.44035911e-17, -5.54194468e-16,  3.23374660e-16,  2.30283792e-15,\n",
              "       -9.75100001e-16, -5.55875346e-16, -8.49529336e-16, -2.10313988e-16,\n",
              "       -2.47004639e-16, -1.34216194e-15,  8.74256223e-16,  2.36015651e-16,\n",
              "       -8.22979462e-16, -4.06519263e-16, -1.96220817e-15,  1.08080211e-16,\n",
              "        1.51324286e-15,  9.38553679e-16, -3.60014241e-16, -5.10065323e-16,\n",
              "       -2.37961872e-15, -1.14221965e-15,  1.04619202e-15, -1.28068001e-15,\n",
              "        2.27775576e-16, -1.63726810e-15, -1.45277346e-15, -2.53934651e-16,\n",
              "        1.91931804e-15, -2.64466227e-16, -2.42852405e-16, -1.76143544e-16,\n",
              "       -1.45716217e-15,  5.09858822e-17,  1.01081810e-15, -1.37288625e-15,\n",
              "       -4.04625222e-16, -4.26707558e-16, -4.44015935e-16, -6.88258339e-16,\n",
              "        3.20263815e-16,  2.27871055e-16, -3.40202755e-15,  3.42141870e-16,\n",
              "       -2.42306175e-16, -8.56514859e-17,  1.62279967e-15, -1.16465282e-15,\n",
              "        5.42597078e-16, -9.43749523e-16,  7.75202125e-17,  8.09790013e-16,\n",
              "       -1.43447920e-15, -1.98935313e-15,  5.66415803e-16, -6.53102017e-16,\n",
              "       -9.67537162e-17, -1.06182618e-15,  7.31630312e-16, -8.17186319e-16,\n",
              "        1.17837740e-15,  1.38239642e-15,  8.42337311e-16, -7.39326378e-16,\n",
              "       -6.85529411e-16, -1.46602730e-15,  5.74535974e-16, -1.84225968e-15,\n",
              "        1.22780786e-15, -4.60879113e-16,  1.19361632e-15,  2.86535240e-16,\n",
              "        9.62385727e-16,  1.64419589e-16,  1.21228805e-15,  1.11285647e-15,\n",
              "       -4.72681894e-16, -1.38143719e-15, -4.10032674e-15,  5.58657565e-16,\n",
              "        6.58195720e-16, -2.35502506e-15, -2.87945223e-16,  5.56732438e-16,\n",
              "        8.97104613e-16,  6.38427977e-15,  1.23118404e-15,  7.23738847e-16,\n",
              "       -2.47034615e-16, -4.90274488e-18, -1.04046771e-15,  9.98705563e-16,\n",
              "       -5.17786924e-16,  2.01687556e-16, -1.73276060e-15,  7.48778817e-16,\n",
              "        3.81792375e-16, -1.60817804e-15,  1.39002365e-15, -1.22469146e-15,\n",
              "        7.67157449e-16,  4.75444129e-16,  1.74609882e-15,  9.62523394e-16,\n",
              "       -2.01025641e-15,  5.29656319e-16, -2.51125343e-15, -1.89397387e-16,\n",
              "       -4.14903667e-16, -7.54230012e-16, -1.80813586e-15,  1.05190967e-15,\n",
              "        1.51519908e-15,  1.44666279e-15, -3.67261777e-16,  1.62605152e-15,\n",
              "       -6.69926337e-16,  5.15720799e-17,  5.64346347e-16, -1.64827929e-15,\n",
              "       -7.23796578e-16, -2.00879313e-16, -1.55557789e-16,  8.37641068e-17,\n",
              "        5.77036197e-16,  7.74333930e-16,  3.24629212e-15,  4.64439598e-16,\n",
              "        4.30380176e-16,  1.88178140e-15, -4.55038229e-16,  3.09205772e-15,\n",
              "       -1.42419410e-15,  6.39313047e-16, -1.20121135e-15,  1.95796712e-16,\n",
              "        1.26051614e-15,  1.36852751e-16, -3.82869292e-16,  2.21473950e-16,\n",
              "       -1.27358790e-15, -4.16287005e-16, -5.68209924e-15, -1.76946235e-15,\n",
              "        1.90158334e-15,  3.31832339e-16,  1.96584971e-16,  1.32619471e-15,\n",
              "       -1.03672626e-17, -7.81243958e-16, -1.02607478e-15,  5.90767435e-16,\n",
              "        8.58220162e-16, -8.40387759e-16, -2.28958408e-15,  1.14912968e-15,\n",
              "        6.69300171e-16,  3.89450694e-16,  1.91666238e-15,  8.94695429e-16,\n",
              "       -2.16034524e-15, -1.06986642e-15, -8.89555096e-16, -7.05824510e-15,\n",
              "        2.22373231e-16,  6.09214901e-16, -1.59909641e-15, -1.00092379e-15,\n",
              "       -1.21928023e-15,  9.96003280e-17,  7.98143773e-16, -3.20383720e-16,\n",
              "       -1.40320422e-15,  1.14073195e-16, -1.19245835e-15,  2.61661248e-15,\n",
              "       -8.59683436e-16, -3.36477513e-16, -2.88017499e-15,  2.33910669e-16,\n",
              "        1.45113699e-15, -2.22970531e-16,  2.81241697e-16, -2.71362044e-15,\n",
              "       -7.16167126e-16,  6.00761663e-16, -3.46194184e-16,  1.05916387e-15,\n",
              "        7.60058683e-18, -5.80957504e-16,  2.11162199e-16, -3.92901267e-16,\n",
              "       -1.05036202e-15, -9.42925737e-16,  4.96735986e-16,  1.31188393e-15,\n",
              "        4.62951899e-16, -4.57354155e-16, -8.15172374e-16,  1.19555033e-15,\n",
              "       -1.18713928e-15,  8.72425465e-16,  8.46549497e-16,  1.63259628e-15,\n",
              "       -1.65449876e-16, -2.32482922e-16,  1.44964041e-16,  1.12997389e-15,\n",
              "        1.16461063e-15,  1.87034832e-16,  7.58570984e-17, -1.59148028e-15,\n",
              "        7.08729742e-16,  7.64206476e-16, -1.33933753e-15, -1.16226140e-15,\n",
              "       -6.96385172e-16, -8.31721358e-16, -3.15669713e-16,  1.03204778e-15,\n",
              "       -4.48713067e-15, -4.47104576e-16,  3.51190188e-16,  3.81921161e-16,\n",
              "       -1.28529853e-15, -3.39968054e-16, -1.01660902e-15,  1.40057743e-15,\n",
              "        1.08048459e-15, -7.29267757e-16, -1.11944232e-15, -1.43718148e-15,\n",
              "       -1.12851506e-15, -4.92599295e-16,  1.50271129e-15,  9.46276391e-16,\n",
              "        1.09838361e-15, -3.72675224e-16,  1.04796172e-15, -1.79962933e-15,\n",
              "       -2.01878958e-15, -4.08428846e-16, -1.09208420e-15, -3.72324394e-17,\n",
              "        2.88049362e-15,  4.66591210e-16,  1.21038957e-15,  4.00370848e-16,\n",
              "        1.03633768e-15, -2.47162291e-16, -1.36179068e-15, -3.39087647e-15,\n",
              "       -1.63911551e-15,  1.75500503e-15, -1.33599798e-16, -1.18780541e-15,\n",
              "       -1.44243284e-15,  5.50011148e-16, -1.31851863e-15,  7.09172721e-16,\n",
              "       -1.79124271e-15, -2.01153538e-16,  1.93948191e-15,  1.78321136e-15,\n",
              "       -1.09379616e-15, -5.62214719e-16,  3.62199160e-17,  1.16454402e-15,\n",
              "        1.16975096e-15,  1.59313229e-15,  4.73725503e-16,  4.82356377e-16,\n",
              "       -1.00860875e-15, -7.86215537e-17, -7.57691687e-16,  2.27989627e-15,\n",
              "       -1.10584208e-15, -7.76596565e-16, -2.05278017e-16, -1.06781251e-17,\n",
              "        3.33555406e-16,  1.27129640e-15,  1.03743236e-15, -9.84470283e-16,\n",
              "        5.51031443e-16, -2.75259815e-16, -5.55548940e-16,  2.62147637e-15,\n",
              "       -7.65607577e-16, -1.97158623e-15, -4.40418813e-16, -1.62436731e-16,\n",
              "       -5.00013364e-16,  6.18908258e-16, -2.78237433e-16,  1.59463553e-16,\n",
              "       -8.10669309e-16,  1.59925406e-15,  5.38702416e-16, -5.32844879e-16,\n",
              "       -1.88827620e-15, -8.24982305e-16,  4.33963976e-17,  7.41338102e-16,\n",
              "       -1.50222057e-16, -7.35118633e-16,  1.90444549e-15,  8.11322121e-16,\n",
              "        2.63892241e-15, -1.85807814e-15,  1.31739064e-17,  1.01789688e-15,\n",
              "        1.46938017e-16, -1.82858173e-16, -4.24904556e-17, -3.92641475e-17,\n",
              "        1.36881395e-15, -2.50485854e-15,  2.39718911e-15, -2.73565615e-15,\n",
              "       -1.97735384e-15,  5.43547429e-16,  6.57525145e-16,  1.09538822e-15,\n",
              "       -4.48323600e-16, -1.66423320e-15,  1.08198006e-15, -1.68041359e-15,\n",
              "       -6.84352575e-16,  2.09742668e-15,  1.26732180e-15, -7.50137730e-16,\n",
              "       -2.24165908e-15, -1.26831878e-17,  3.83499899e-16, -1.08040021e-15,\n",
              "        1.06356257e-15,  1.33883127e-15,  1.00962794e-15,  7.48695550e-17,\n",
              "       -4.75559592e-16, -5.40136824e-16, -1.64961156e-15, -7.45425943e-16,\n",
              "        8.71835937e-17,  1.28401734e-15,  6.19442275e-16,  9.26689836e-16,\n",
              "       -1.34119160e-15,  3.41999762e-16,  6.82545132e-16,  9.48290335e-16,\n",
              "        2.41806575e-18,  1.18979049e-15, -1.00420117e-15, -1.25283561e-15,\n",
              "       -5.44246870e-16, -7.51200213e-16,  6.67814692e-16,  1.33583811e-15,\n",
              "       -7.16937620e-16,  1.02368780e-15, -1.58266955e-15, -1.04375619e-15,\n",
              "        9.05160391e-16,  4.12834211e-16, -9.05011621e-16, -1.73718817e-16,\n",
              "       -1.58068891e-15, -2.53648880e-15,  1.00627284e-15,  6.38162856e-16,\n",
              "        2.86599633e-16, -9.16777765e-17,  3.02535774e-17,  1.06917808e-16,\n",
              "        2.91735525e-16, -3.28341798e-16, -5.23738830e-16, -3.33812977e-16,\n",
              "       -1.21620491e-16, -2.52231569e-16, -7.31015248e-16,  1.37951872e-16,\n",
              "       -1.41607170e-15, -1.01416653e-15, -8.90023610e-16,  1.12805765e-15,\n",
              "       -3.14532844e-16, -1.22214683e-15, -1.01070485e-15, -1.15358390e-15,\n",
              "       -7.26041449e-16, -1.38249856e-15,  3.45347750e-15,  3.38922224e-16,\n",
              "        1.14007692e-15,  6.26778629e-16,  1.19417143e-15, -2.44956722e-15,\n",
              "        1.21798793e-15, -1.89707361e-15, -2.27687202e-15, -1.30718991e-15,\n",
              "        1.00311759e-15,  1.98766781e-15,  1.06439302e-15, -3.01040304e-16,\n",
              "        2.19589458e-15,  1.10560450e-15, -1.01798570e-15, -3.06977332e-15,\n",
              "       -8.22524271e-16, -2.59670063e-16,  1.25355282e-16,  7.04492020e-16,\n",
              "        1.13718812e-15,  2.80078183e-16,  1.64551039e-15, -2.18642882e-16,\n",
              "       -2.51466181e-15, -1.60172098e-15,  3.02755598e-15,  2.20903740e-15,\n",
              "       -1.09747988e-15, -1.59738889e-16,  8.49416093e-16, -4.29913882e-16,\n",
              "       -3.74734022e-15, -1.53650426e-16, -1.79010806e-15, -1.44925405e-15,\n",
              "       -5.49391643e-16, -1.12170162e-15, -5.60218538e-16,  3.29016814e-16,\n",
              "       -1.46159751e-15,  8.63301652e-16, -3.56308316e-16,  1.82002857e-15,\n",
              "        2.51065835e-15,  1.13661969e-15, -1.76380688e-15,  5.83815218e-16,\n",
              "       -5.17070831e-16, -5.21376275e-16, -1.93126404e-15,  9.69251346e-16,\n",
              "       -6.55966392e-16, -1.23568489e-15,  2.45599097e-15, -6.86774193e-15,\n",
              "        6.86500856e-16,  1.63287162e-16,  1.70159664e-15,  2.20597984e-15,\n",
              "        7.91411381e-16, -1.50042201e-16,  1.75524040e-16, -8.47142356e-16,\n",
              "        1.28497879e-15, -4.69668748e-16,  1.36204381e-16,  2.69030576e-15,\n",
              "       -7.01880776e-16,  3.12105897e-16,  9.38471523e-17, -1.47222234e-16,\n",
              "       -3.47037954e-15,  6.02902173e-16,  8.33608738e-16, -2.64663846e-16,\n",
              "        5.77219383e-16,  1.45618739e-15, -6.68601841e-16, -1.00374598e-15,\n",
              "        1.86462401e-15, -1.16314514e-15,  1.59730895e-15,  8.53344062e-16,\n",
              "        5.96656058e-16, -1.04442677e-15, -2.02925454e-16, -8.33786373e-16,\n",
              "        9.24011978e-16,  9.02002917e-16,  1.84334104e-15, -6.03073147e-17,\n",
              "       -1.03340447e-15, -2.83826296e-16, -7.58724195e-16,  2.95710123e-16,\n",
              "        1.08416609e-15, -1.03856035e-15, -1.77489801e-15, -1.05960574e-15,\n",
              "        1.73201453e-16, -6.54776233e-16, -9.27702359e-16, -5.81446002e-16,\n",
              "       -3.40424133e-15,  6.76334544e-16, -2.73867595e-16,  5.23097787e-15,\n",
              "       -2.44375631e-16, -2.24971375e-15,  3.12749826e-17,  4.53173055e-16,\n",
              "       -1.93089988e-16, -7.59179386e-16,  6.82813805e-16, -5.33706412e-16,\n",
              "       -4.21496171e-16,  4.49795756e-17,  1.16467946e-15, -5.82505155e-16,\n",
              "        1.09214859e-16,  2.23773444e-15, -2.71138667e-17, -7.70310482e-16,\n",
              "        4.18356461e-16, -9.36841715e-16,  1.44698586e-15,  1.06401998e-15,\n",
              "        1.04914522e-15, -2.58312260e-15,  7.55642215e-16, -3.10935722e-16,\n",
              "        9.71960290e-16,  2.33257857e-17, -3.64308583e-16,  2.78248535e-16,\n",
              "       -1.63141722e-15,  4.65323335e-16, -4.23623359e-16, -1.02115205e-15,\n",
              "       -6.86162238e-16, -4.75788298e-16,  9.35935773e-16,  9.26907440e-16,\n",
              "        7.00073333e-16,  3.79041243e-16,  7.58149099e-17, -1.67277303e-16,\n",
              "       -2.23763452e-15,  8.38360492e-16,  1.68302039e-15,  1.02019726e-15,\n",
              "        9.48963130e-17,  5.51179102e-16,  3.73008291e-16, -1.38488554e-15,\n",
              "        6.85924650e-16,  3.27184946e-16,  1.05352838e-15,  1.64939395e-15,\n",
              "        1.44929624e-15,  1.56511248e-15,  4.39790426e-16,  1.87741378e-15,\n",
              "       -1.51401114e-16,  2.72324163e-15, -1.42108547e-16,  2.35022668e-15,\n",
              "       -4.60822491e-16, -1.12226672e-15,  1.55883084e-15, -1.58177471e-15,\n",
              "       -2.27113661e-15, -8.98845443e-16, -7.07811587e-17, -2.01738626e-16,\n",
              "       -1.41635592e-16, -1.40502721e-15, -1.10293774e-15, -1.22237553e-15,\n",
              "       -1.43516310e-15, -6.65413280e-16,  4.86695129e-16,  1.13693499e-16,\n",
              "       -3.86939369e-16,  5.41815481e-16,  2.00647277e-15,  1.12564180e-15,\n",
              "        1.14408927e-15,  4.73781014e-16, -9.16053899e-16,  1.15497834e-15,\n",
              "        2.52118326e-16,  1.58177693e-15,  1.40292666e-15,  2.65411471e-15,\n",
              "        1.07579057e-15,  1.59550373e-15,  4.06761291e-16, -2.40285569e-16,\n",
              "        8.04534217e-17,  8.93869423e-16,  6.32200958e-16, -1.40735423e-15,\n",
              "        4.31885638e-16, -3.19140270e-16,  2.27768915e-16,  8.37019343e-16,\n",
              "       -5.26467758e-18,  1.48290269e-16,  2.39102071e-16,  1.58175029e-15,\n",
              "        1.61453517e-15,  2.45592435e-16, -9.89763826e-17,  2.20072849e-16,\n",
              "        2.73541190e-16, -3.11662252e-15,  1.16726406e-15,  2.93984836e-16,\n",
              "        3.19273497e-16,  1.36010758e-15, -2.82966983e-16, -1.18283827e-15,\n",
              "       -3.68651776e-16,  2.52614596e-15, -8.19756485e-16,  4.02665679e-16,\n",
              "       -6.64406308e-16, -1.80826687e-15, -9.33659816e-16, -1.17425181e-15,\n",
              "       -3.69859698e-16, -8.83602080e-16,  5.16653387e-17, -2.62442290e-16,\n",
              "       -2.40951703e-16,  2.25333086e-16, -3.49569262e-16,  5.58291191e-16,\n",
              "        1.95135019e-16, -1.39682488e-15, -1.25318422e-15, -2.10450768e-15,\n",
              "       -4.56377158e-16, -1.10947029e-15, -1.22301502e-15, -6.94431179e-16,\n",
              "        4.87022200e-15, -1.13918652e-15, -6.52899956e-17, -3.75317555e-16,\n",
              "        1.26277877e-15, -7.96785971e-16, -2.44031462e-16,  1.53110857e-16,\n",
              "       -2.63351119e-15,  3.94773103e-17, -4.45332660e-16, -7.33453298e-16,\n",
              "       -1.10809140e-16,  4.00213196e-17, -2.56380028e-15,  4.46653825e-16,\n",
              "        5.79485349e-16,  1.15952137e-15, -3.00082181e-17,  5.23761035e-16,\n",
              "       -9.05469033e-16,  5.40134604e-16, -1.23445476e-15, -2.01105799e-17,\n",
              "       -7.68722863e-16,  1.18407950e-15,  1.15985443e-15, -3.78974629e-16,\n",
              "       -1.32738043e-15,  3.47761819e-16, -3.97466504e-16, -1.50528034e-15,\n",
              "       -5.69277958e-16,  1.46389567e-15, -9.17048659e-16,  8.91813290e-16,\n",
              "        1.92474037e-15,  1.96540784e-15,  1.57257984e-15,  1.32247324e-15,\n",
              "        2.23163710e-16,  2.63908895e-16,  9.42645961e-16, -5.14754905e-17,\n",
              "        2.46147547e-15, -1.07784670e-15,  1.04528608e-15, -1.98841388e-15,\n",
              "        8.34052827e-16, -1.35315759e-15,  4.50237625e-16,  7.30793204e-16,\n",
              "       -4.65065764e-16, -7.37252481e-16,  4.61204408e-16, -2.71648704e-15,\n",
              "        1.02251541e-17,  6.07587314e-16,  1.12117204e-15,  1.64812608e-16,\n",
              "        1.48451917e-15,  1.54324997e-15, -5.17383913e-16,  1.51905155e-16,\n",
              "       -7.62190311e-16,  1.29079858e-15, -2.12947437e-16, -2.10176765e-15,\n",
              "        1.01697983e-15,  1.18683730e-15, -1.02718056e-15,  9.08508824e-16,\n",
              "        7.43349826e-16, -5.92113025e-16,  2.59320121e-15, -6.71107614e-16,\n",
              "        5.94624350e-16,  9.58246815e-16,  1.31591182e-15, -5.07902609e-16,\n",
              "       -2.17807772e-15, -6.39570619e-16, -1.09645626e-15, -6.44924114e-16,\n",
              "        3.87543331e-16,  4.54729587e-16, -6.00821615e-16, -7.77637954e-16,\n",
              "        1.28648203e-16, -5.05835374e-16, -3.03977954e-16, -1.07331033e-15])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z47N4iv7c4HA",
        "colab_type": "text"
      },
      "source": [
        "<div id=\"top_of_steps\"></div>\n",
        "# Steps\n",
        "1. <a href=\"#Implement-logistic-regression-likelihood.\">Implement logistic regression likelihood.</a>\n",
        "2. <a href=\"#Compute-derivative-of-logistic-regression.\">Compute derivative of logistic regression.</a>\n",
        "3. <a href=\"#Check-gradient.\">Check gradient.</a>\n",
        "4. <a href=\"#Tweak-gradient-ascent-code.\">Tweak gradient ascent code.</a>\n",
        "5. <a href=\"#Report-results-and-analysis.\">Report results and analysis.</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvkaqh1yc4HA",
        "colab_type": "text"
      },
      "source": [
        "# Implement logistic regression likelihood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAseMQMMc4HB",
        "colab_type": "text"
      },
      "source": [
        "Data is given as $D = {(\\mathbf{x}_i, y_i):, i = 1...n}$, where $y_i \\in \\{-1, +1\\}$, and $\\mathbf{x}_i \\in R^p$. In this case there are n samples and each sample has p features. <br \\>\n",
        "\n",
        "For logistic regression, \n",
        "* We have model parameters: $\\mathbf{w} \\in R^p$ for weight and a bias term $b$.\n",
        "* For a sample x and its label y, $p(y|\\mathbf{x}, \\mathbf{w}, b) = \\frac{1}{1+exp\\{-y(\\mathbf{w} \\cdot \\mathbf{x} + b)\\}}$ \n",
        "* We can define $x' = \\begin{bmatrix} 1\\\\ x \\end{bmatrix}$, then $ \\mathbf{w}' =  \\begin{bmatrix} b\\\\ \\mathbf{w} \\end{bmatrix}$. Therefore the bias term is included in the weight vector. For notation brevity, we still use notations $x, \\mathbf{w}$ as $x', \\mathbf{w}'$. This can be implemented by numpy.concatenate function.\n",
        "* Hence the first entry of the vector $w'$ is bias term and the rest are feature weights. In the code you can use w[0] to access the bias term and w[1:] to access the feature weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNZZjAqic4HB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "#We help you do the concatenate, so the first feature becomes the  bias term\n",
        "train_data_pad = np.concatenate( ( np.ones((trainData.shape[0], 1)), trainData ), axis = 1 )\n",
        "test_data_pad = np.concatenate( ( np.ones((testData.shape[0], 1)), testData ), axis = 1 )\n",
        "valid_data_pad = np.concatenate( ( np.ones((validData.shape[0], 1)), validData ), axis = 1 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lo1x2z7c4HG",
        "colab_type": "text"
      },
      "source": [
        "## To-do: \n",
        "1. Given the data $D = {(\\mathbf{x}_i, y_i)} $, write down the likelihood function ($L(\\mathbf{w})$) of logistic regression. ** [1 pt] **\n",
        "2. Take $\\log$ of the likelihood function in (1), write down the log likelihood function. Hint: $\\log$ will not cancel $\\exp$. ** [1 pt] **\n",
        "3. Add  ridge penalty in the log likelihood function (Let the weight of ridge penalty be $\\alpha$). Hint: Do not include $w_0$ in the ridge term. ** [1 pt] **\n",
        "4. Write a function to compute regularized log likelihood ** [1 pt] **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WEogX95c4HG",
        "colab_type": "text"
      },
      "source": [
        "1. $ L(\\mathbf{w'}) =  \\displaystyle\\prod_{i}\\frac{1}{1+exp\\{-y_i(\\mathbf{w'} \\cdot \\mathbf{x_{i}'} )\\}}$ \n",
        "2. $ LL(\\mathbf{w'}) = -\\sum_i^{N} log(1+exp(-y_i(\\mathbf{w'} \\cdot \\mathbf{x_{i}'} )))$\n",
        "3. $ PLL(\\mathbf{w'}) = -\\sum_{i}^{N} log(1+exp(-y_i(\\mathbf{w'} \\cdot \\mathbf{x_i'}))  - \\frac{\\alpha}{2}\\sum_{j=1}^{p} \\mathbf{w_{j}'}^2 $\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAFbB3cKc4HH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def loglikelihood(w, X, y, alpha): \n",
        "    #compute loglikelihood for current w, b, given the data X, y\n",
        "    #w is a vector, b is a scalr, X is a n*p matrix and y is a vector.\n",
        "    arrn1 = np.dot(X,w) #arrn1 is nx1 array\n",
        "    temparr = np.ones(len(y)).transpose()  #arry of ones columns nx1\n",
        "    np.multiply(-y, arrn1, temparr)\n",
        "   # for i in range(len(y)):\n",
        "   #   temparr[i] = -y[i]*arrn1[i]\n",
        "    tmp = np.log(1. + np.exp(temparr))\n",
        "    return -np.sum( tmp ) - (alpha/2.)*np.sum( np.dot(w[1:], w[1:]) ) #indexing starts at 1 bc we watnt to avoid including B0 in penalty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UPjN3pfc4HP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b3f420a-7edd-4d9f-c143-5ba657b5243e"
      },
      "source": [
        "# testing\n",
        "np.random.seed(1)\n",
        "X = np.random.randn(2,3)\n",
        "y = np.array([1,-1])\n",
        "w = np.ones(3)\n",
        "w[[1]] = -1;\n",
        "loglikelihood(w, X, y, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.1808712118395306"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mimAN24c4HT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1dc04e31-5cb0-4e68-9922-fec812f86626"
      },
      "source": [
        "#the values printed in this cell should be the same as the value printed in the previous cell.\n",
        "print( -np.log(1+np.exp(-1*(X[0,0]-X[0,1]+X[0,2]))) - np.log(1+np.exp(1*(X[1,0]-X[1,1]+X[1,2]))) -1/2.*np.sum(w[1:]**2) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1.1808712118395306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8dvoKvEc4HW",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"#top_of_steps\">top</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-XcaXVRc4HX",
        "colab_type": "text"
      },
      "source": [
        "# Compute derivative of logistic regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIt1TUq5c4HX",
        "colab_type": "text"
      },
      "source": [
        "In order to optimize the function, we want to take the derivative of the function, and update $\\mathbf{w}$ according to the direction of the gradient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twYXd16Ic4HY",
        "colab_type": "text"
      },
      "source": [
        "## To-do:\n",
        "1. Write down the derivative of the **penalized log likelihood function** for each $ w_j $. Hint: Remember that bias term is $w_0$ and treat it separately from the rest of $w_j$, $j\\in\\{1,...,p\\}$ ** [1 pt] **\n",
        "2. Write down the gradient of log likelihood function. Hint: You can express this in terms of probabilities. ** [1 pt] **\n",
        "3. Update the loglikelihood function to return both the loglikelihood and the gradient. ** [1 pt] **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyB60z_5c4HY",
        "colab_type": "text"
      },
      "source": [
        "1. \n",
        "$ \\frac{\\partial PLL(\\mathbf{w'})}{ \\partial \\mathbf{w_0}} = \\sum_i^N \\frac{y_iexp{(-y_i\\mathbf{w'x_i})}}{1+exp{(-y_i\\mathbf{w'x_i'})}}$  \n",
        "\n",
        "\n",
        "> \n",
        "\n",
        "$ \\frac{\\partial PLL(\\mathbf{w'})}{ \\partial \\mathbf{w_j}} = \\sum_i^N \\frac{y_i\\mathbf{x_{ij}'}exp{(-y_i\\mathbf{w'x_i'})}}{1+exp{(-y_i\\mathbf{w'x_i'})}} $ \n",
        "$  - \\alpha\\mathbf{w_j'}, j>0$ \n",
        ">\n",
        "2. <br \\>\n",
        "$ \\nabla PLL(\\mathbf{w}) = \\sum_i^N y_i\\begin{bmatrix}  \\\\\\frac{exp{(-y_i\\mathbf{w'x_i})}}{1+exp{(-y_i\\mathbf{w'x_i'})}} \\\\\\frac{\\mathbf{x_{ij}'}exp{(-y_i\\mathbf{w'x_i'})}}{1+exp{(-y_i\\mathbf{w'x_i'})}} \\\\ \\vdots \\\\ \\frac{\\mathbf{x_{ip}'}exp{(-y_i\\mathbf{w'x_i'})}}{1+exp{(-y_i\\mathbf{w'x_i'})}} \\end{bmatrix} - \\alpha\\begin{bmatrix}  \\\\ 0 \\\\ w_{j} \\\\ \\vdots \\\\ w_{p}\\\\ \\end{bmatrix},  j>0 $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWF3LKDRRLMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def loglikelihood(w, X, y, alpha): \n",
        "    #compute loglikelihood for current w, b, given the data X, y\n",
        "    #w is a vector, b is a scalr, X is a n*p matrix and y is a vector.\n",
        "    #########\n",
        "    xw = np.dot(X,w) #xw is nx1 array\n",
        "    neg_yxw = np.ones(len(y)).transpose()  #arry of ones columns nx1\n",
        "    for i in range(len(y)):\n",
        "      neg_yxw[i] = -y[i]*xw[i]\n",
        "    tmp = 1. + np.exp(neg_yxw, dtype = np.longdouble)\n",
        "    penalty = (alpha/2.)*np.sum( np.dot(w[1:], w[1:]), dtype = np.longdouble )\n",
        "    ##########\n",
        "   \n",
        "    X = X.T #X becomes a p*n matrix so the gradVal can be compute straight-forwardly.\n",
        "    gradVal = np.ones(len(w)).transpose() # empty gradient\n",
        "    gradPenalty = np.ones(len(w)).transpose() # empty gradPenalty (bias term has no penalty)\n",
        "\n",
        "    numerator = np.ones(len(y)).transpose() # empty vector for numerator of summations\n",
        "    #Gradient for rest of weights:\n",
        "    for (i) in range(len(w)-1):\n",
        "      np.multiply(y, X[i+1],numerator, dtype = np.longdouble)\n",
        "      np.multiply(numerator, np.exp(neg_yxw), numerator, dtype = np.longdouble)\n",
        "      np.divide(numerator, tmp, numerator, dtype = np.longdouble)\n",
        "      gradVal[i+1] = np.sum(numerator, dtype = np.longdouble) # sum((yxexp(-ywx'))/(1+exp(-ywx')))   \n",
        "      gradPenalty[i+1] = -alpha*w[i+1]     \n",
        "\n",
        "    gradPenalty[0] = 0 #(bias term has no penalty) \n",
        "\n",
        "    #The gradient for the bias term:\n",
        "    np.multiply(y, np.exp(neg_yxw),numerator, dtype = np.longdouble)\n",
        "    np.divide(numerator, tmp, numerator, dtype = np.longdouble)\n",
        "    gradVal[0] = np.sum(numerator, dtype = np.longdouble) #sum((y*exp(-ywx'))/(1+exp(-ywx'))); BIAS TERM GRAD\n",
        "\n",
        "    return -np.sum( np.log( tmp , dtype = np.longdouble), dtype = np.longdouble ) - penalty, gradVal + gradPenalty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZRO9WJfc4Hb",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"#top_of_steps\">top</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHd-ZruKc4Hc",
        "colab_type": "text"
      },
      "source": [
        "# Check gradient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw8l5AJOc4Hc",
        "colab_type": "text"
      },
      "source": [
        "It is very important we know the derivative we computed is correctly. We can check it by comparing it with numerical answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaNL_y94c4Hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %load grad_check.py\n",
        "def grad_check(f,xy0,delta=1e-6,tolerance=1e-7):\n",
        "    f0,g0 = f(xy0)\n",
        "    p = len(xy0)\n",
        "    finite_diff = np.zeros(p)\n",
        "    gradient_correct = True\n",
        "    for i in range(p):\n",
        "        xy1 = np.copy(xy0)\n",
        "        xy2 = np.copy(xy0)\n",
        "        xy1[i] = xy1[i] - 0.5*delta\n",
        "        xy2[i] = xy2[i] + 0.5*delta\n",
        "        f1,_ = f(xy1)\n",
        "        f2,_ = f(xy2)\n",
        "        finite_diff = (f2 - f1)/(delta)\n",
        "        if (abs(finite_diff - g0[i])>tolerance):\n",
        "            print(\"Broken partial\",i,\" Finite Diff: \",finite_diff,\" Partial: \",g0[i])\n",
        "            gradient_correct = False\n",
        "    return gradient_correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eDiv4iQc4Hf",
        "colab_type": "text"
      },
      "source": [
        "* We initialize the w vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akPbktfic4Hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w_init = np.random.randn( train_data_pad.shape[1] )*0.001\n",
        "w_init[0] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLOdTqIRc4Hj",
        "colab_type": "text"
      },
      "source": [
        "## To-do:\n",
        "* Here is the code to test if your gradient computation is correct (If the result is true, you get **1 pt**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BRb2bSezc4Hk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b75c882a-574d-4b26-b53c-758968e2709a"
      },
      "source": [
        "g = lambda xy0: loglikelihood(xy0, X=train_data_pad[:,:15], y=trainLabel, alpha=1)\n",
        "grad_check( g, w_init[:15], delta=1e-6, tolerance=1e-5 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMnCExVwc4Ho",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"#top_of_steps\">top</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p6WjXdxc4Hp",
        "colab_type": "text"
      },
      "source": [
        "# Tweak gradient ascent code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwAiQBbcc4Hp",
        "colab_type": "text"
      },
      "source": [
        "Here we provide the gradient ascent function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jolypiO2c4Hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# %load gradient_ascent\n",
        "def gradient_ascent(f,x,init_step,iterations):  \n",
        "    f_val,grad = f(x)                           # compute function value and gradient \n",
        "    f_vals = [f_val]\n",
        "    for it in range(iterations):                # iterate for a fixed number of iterations\n",
        "        #print 'iteration %d' % it\n",
        "        done = False                            # initial condition for done\n",
        "        line_search_it = 0                      # how many times we tried to shrink the step\n",
        "        step = init_step                        # reset step size to the initial size\n",
        "        while not done and line_search_it<100:  # are we done yet?\n",
        "            new_x = x + step*grad               # take a step along the gradient\n",
        "            new_f_val,new_grad = f(new_x)       # evaluate function value and gradient\n",
        "            if new_f_val<f_val:                 # did we go too far?\n",
        "                step = step*0.95                # if so, shrink the step-size\n",
        "                line_search_it += 1             # how many times did we shrank the step\n",
        "            else:\n",
        "                done = True                     # better than the last x, so we move on\n",
        "        \n",
        "        if not done:                            # did not find right step size\n",
        "            print(\"Line Search failed.\")\n",
        "        else:\n",
        "            f_val = new_f_val                   # ah, we are ok, accept the new x\n",
        "            x = new_x\n",
        "            grad = new_grad\n",
        "            f_vals.append(f_val)\n",
        "        plt.plot(f_vals)\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Function value')\n",
        "    return f_val, x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1R4yCFnc4Ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(12345)\n",
        "w_init = np.random.randn( train_data_pad.shape[1] )*0.001\n",
        "w_init[0] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69xaJ8W8c4Hv",
        "colab_type": "text"
      },
      "source": [
        "## To-do:\n",
        "* Try different init_step (1e-4, 1e-5, 1e-6) using the following code, report the final regularized log-likelihood values. **[1 pt]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGZmeIjnc4Hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimizeFn( init_step, iterations, alpha, w):\n",
        "    g = lambda xy0: loglikelihood(xy0, train_data_pad, trainLabel, alpha)\n",
        "    f_val, update_w = gradient_ascent( g, w, init_step, iterations )\n",
        "    return f_val, update_w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kBHPnQQAc4Hy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "6d2a7c28-2dd4-4790-bcc3-742e48e86245"
      },
      "source": [
        "print ('This should take about 6 seconds.')\n",
        "start = time.time()\n",
        "f_val, update_w=optimizeFn( init_step = 1e-6, iterations=100, alpha=0, w = w_init) #set init_step to 1e-4, 1e-5, 1e-6\n",
        "end = time.time()\n",
        "print ('Time elapsed (seconds):', end-start)\n",
        "print ('final log-likelihood = %f\\n' % (f_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This should take about 6 seconds.\n",
            "Time elapsed (seconds): 59.81230068206787\n",
            "final log-likelihood = -4707.155301\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRG9UOXdc4H2",
        "colab_type": "text"
      },
      "source": [
        "Final regularized log-likelihood values for (1e-4, 1e-5, 1e-6) are: \n",
        ">\n",
        " - 1e-4: -2602.170368\n",
        " - 1e-5: -3033.038249\n",
        " - 1e-6: -4707.155301"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG01sWXac4H3",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"#top_of_steps\">top</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI3h8GHmc4H4",
        "colab_type": "text"
      },
      "source": [
        "# Report results and analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpUS3UXSc4H4",
        "colab_type": "text"
      },
      "source": [
        "To evaluate the results, we need to have a prediction function, that uses the model we trained to predict the comment is positive and negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMp2HWFfc4H5",
        "colab_type": "text"
      },
      "source": [
        "## To-do:\n",
        "1. Implement the prediction function. It should take as inputs feature weights and feature matrix. It should return vector of labels. **[1 pt]**\n",
        "2. Try different alpha (1000, 2000, 3000), and report which alpha produces the model that has the best accuracy on the validation set **[1 pt]**\n",
        "2. **[optional]** Report one sample that is classified wrong with high probabilites (> 90%). **[1 pt]**\n",
        "3. **[optional]** Report the words (entries in vocab_list associated with that feature) that cause the sample reported in (2) classify wrong. Note that weight w[i] correponds to word vocab_list[i-1], because we included bias term in w.**[1 pt]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXkgs8BQc4H6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction(w, validData ):\n",
        "    prob = 1./(1+ np.exp(-np.dot(validData,w)));    \n",
        "    res = np.zeros(validData.shape[0])\n",
        "    res[prob>=0.5] = 1\n",
        "    res[prob<0.5] = -1\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "FRU6s8X4c4H8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "98f3f8e1-f649-4e94-9a74-a715eaa6b0a5"
      },
      "source": [
        "#see the accuracy on the validation set\n",
        "#when init_step=1e-5, the model has the best accuracy in the validation set\n",
        "f_val, update_w=optimizeFn( init_step = 1e-5, iterations=100, alpha=3000, w=w_init) #try different alphas [1000, 2000, 3000]\n",
        "pred = prediction(update_w, valid_data_pad)\n",
        "print( 'accuracy on the validation set {:.2f}%'.format( 100.*np.mean(pred==validLabel)) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy on the validation set 84.74%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnS0HXEic4H_",
        "colab_type": "text"
      },
      "source": [
        "The best alpha is 3000, and the accuracy of this alpha is: 84.74%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW9icklhc4IA",
        "colab_type": "text"
      },
      "source": [
        "* Report one sample (sample index in the validation data set) that is classified wrong with high probabilites\n",
        "\n",
        "##TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-iisdBzc4IA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrong_idx = np.nonzero( validLabel != pred )[0] #use this command to get the samples that are predicted wrong\n",
        "correct_idx = np.nonzero( validLabel == pred )[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlBkT2jJtCJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6087ecb6-5218-464e-c3a6-ad217d18a02c"
      },
      "source": [
        "wrong_idx.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(763,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A92KphTuc4ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#implement the function to compute probability\n",
        "def computeProb(w, validData ):\n",
        "    prob = 1./(1+ np.exp(-np.dot(validData,w))); \n",
        "    return prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yMvraA1c4IH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2525ad75-6baa-49c2-b2d3-2e3ab514759c"
      },
      "source": [
        "#get the samples that are classified wrong and with probabilites > 0.9\n",
        "probs = computeProb(update_w, valid_data_pad)\n",
        "wrong_idx_high = []\n",
        "for i in range(len(probs)):\n",
        "  if i in wrong_idx and probs[i]>0.9:\n",
        "    wrong_idx_high.append(i)\n",
        "wrong_idx_high"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2027, 2257, 3204]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2LH4fLWc4IM",
        "colab_type": "text"
      },
      "source": [
        "The sample index is 2027 (see above for more indexes with high probablities and wrong classifications)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11S-w2sdc4IM",
        "colab_type": "text"
      },
      "source": [
        "* Report the words that cause the sample reported in (2) classify wrong."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwz2ZQzFc4IN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Use this function to get the most important words for each sample index\n",
        "#This function returns a list of top 10 words that influence the prediction.\n",
        "def getMostImportantFeatures( sampleIdx, validData, update_w, vocab_list ):\n",
        "    confusedList = []\n",
        "    intensity = validData[sampleIdx,:]*update_w\n",
        "    tmp = np.argsort( np.abs(intensity[:]) )[::-1]\n",
        "    for j in np.arange(10):\n",
        "        confusedList.append(vocab_list[tmp[j]-1])\n",
        "    return confusedList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcE-qU6Ic4IP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "ab1409d0-412f-48d4-fc2a-080ae01d1f8e"
      },
      "source": [
        "confusedList = getMostImportantFeatures(2027, valid_data_pad, update_w, vocab_list) #use the sample index got from the previous result\n",
        "confusedList"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['favorite',\n",
              " 'songs',\n",
              " 'could',\n",
              " 'great',\n",
              " 'nothing',\n",
              " 'loved',\n",
              " 'perfect',\n",
              " 'completely',\n",
              " 'us',\n",
              " 'think']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOebErknc4IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load file ids\n",
        "if not os.path.isfile('train_id.pgz'):\n",
        "    U.urlretrieve( \"https://sakai.unc.edu/access/content/group/c4f84923-328b-429b-a8dc-a340b0284e41/HW1/train_id.pgz\", \"train_id.pgz\" );\n",
        "train_id = pickle.load( gzip.open( \"train_id.pgz\", \"rb\" ) )\n",
        "valid_id = train_id[10000:15000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PAMjukyc4Ib",
        "colab_type": "text"
      },
      "source": [
        "* Retrieve the whole review and check if it is hard to classify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNMakOAQc4Ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fileName = valid_id[100]\n",
        "fileUrl = \"https://wwwx.cs.unc.edu/Courses/comp755-f18/hw1/reviews/\" + fileName + '.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRR50Vpmc4Ig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ff716ed-5183-49c3-d5be-cbed5cfea56e"
      },
      "source": [
        "U.urlretrieve(fileUrl, fileName)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('731_9', <http.client.HTTPMessage at 0x7fdb3265a400>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3ESjmMHNU7P",
        "colab_type": "text"
      },
      "source": [
        "## TODO: figure out what end stuff needs to be done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "RCm2a0Lec4Ik",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"#top_of_steps\">top</a>"
      ]
    }
  ]
}